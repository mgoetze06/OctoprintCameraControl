{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "db0db830-9381-4b05-b98e-f539704775be",
      "metadata": {
        "id": "db0db830-9381-4b05-b98e-f539704775be"
      },
      "source": [
        "---\n",
        "\n",
        "# 8801-CVML Advanced - SS22\n",
        "\n",
        "## Assignment 4 - Logistische Regression\n",
        "\n",
        "Dr. Mirco Fuchs, HTWK Leipzig\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "430ab943-988f-4c29-8477-201fd0999264",
      "metadata": {
        "id": "430ab943-988f-4c29-8477-201fd0999264"
      },
      "source": [
        "# Logistische Regression mit linear separierbaren Daten\n",
        "\n",
        "Stellen Sie sich vor, Sie belegen im Rahmen Ihres Studiums an der Fakultät FING der HTWK Leipzig den Kurs \"Maschinelles Lernen\". Im Laufe des Kurses müssen Sie zwei bewertete Assignments einreichen, um für die Abschlussprüfung zugelassen zu werden. In jedem Assignment können Sie bis zu 100 Punkte erreichen. Auf Basis der von Ihnen in beiden Tests erreichten Punktzahl möchten Sie ermitteln, wie ihre Chancen stehen, den Kurs erfolgreich zu absolvieren. Hierzu liegt Ihnen eine anonymisierte Statistik vergangener Kurse vor, d.h. Informationen darüber, welche Punktzahlen in beiden Tests erreicht wurden und ob der Kurs am Ende erfolgreich bestanden wurde. Diese Daten können Sie zum Trainieren einer logistischen Regression verwenden.\n",
        "\n",
        "In dieser Aufgabe werden Sie ein Klassifikationsmodell trainieren, das auf Basis der in den Assignments erreichten Punkte die Wahrscheinlichkeit für das Bestehen des Kurses vorhersagt. Für die konkrete Umsetzung werden Sie einerseits das im letzten Assignment für die lineare Regression realisierte Gradient-Descent-Verfahren erweitern. Andererseits werden Sie das Verfahren der logistische Regression mithilfe von sklearn umsetzen.\n",
        "\n",
        "Die einzelnen Schritte des Assignments sind nachfolgend vorab zusammengefasst:\n",
        "- Einlesen und Visualisieren der Daten\n",
        "- Realisierung der Hypothesen-Funktion des logistischen Regressionsverfahrens\n",
        "- Erweiterung des Gradient-Descent-Verfahrens aus der linearen Regression für die logistische Regression\n",
        "- Darstellung der Entscheidungsgrenzen des Klassifikationsproblems\n",
        "- Umsetzung der Logistische Regression linear separierbarer Daten mit sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed09c157-5224-45ff-9fbd-b4be968b3ceb",
      "metadata": {
        "id": "ed09c157-5224-45ff-9fbd-b4be968b3ceb"
      },
      "source": [
        "## Einlesen der Daten\n",
        "Die historischen Daten liegen in tabellarischer Form in einer txt-Datei vor (`assignment_scores.txt`). Erste und zweite Spalte repräsentieren die im ersten und zweiten Assignment erreichten Punkte, Spalte 3 die Information, ob die Prüfung bestanden wurde. In jeder Zeile befinden sich die zu einer bzw. einem Studierenden gehörenden Daten, die Spalten sind dabei mit einem Komma separiert.\n",
        "\n",
        "### Aufgabe\n",
        "Verwenden Sie die numpy-Funktion `genfromtxt()`, um die Tabellendaten in ein numpy-Array einzulesen. Mit dem Argument `delimiter` dieser Funktion können Sie das Textzeichen definieren, das in der Tabelle der txt-Datei zur Spaltentrennung verwendet wurde. Lesen Sie die Daten ein und speichern Sie diese in der Variable `data`. Wir verzichten in diesem Assignment vollständig auf die Trennung von Trainings-, Validierungs- und Testdaten.\n",
        "\n",
        "### Ergebnis\n",
        "- **data**:  Daten für das Training der logistischen Regression\n",
        "- Dimensionen des numpy-Arrays:\n",
        "  - Spalte 1: Punktzahl im Assignment 1\n",
        "  - Spalte 2: Punktzahl im Assignment 2\n",
        "  - Spalte 3: Prüfung bestanden ($y=1$) / nicht bestanden ($y=0$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e94c5f2-62e0-4160-b6c1-4cc1e82c6b0d",
      "metadata": {
        "id": "6e94c5f2-62e0-4160-b6c1-4cc1e82c6b0d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd2e94c0-fce0-48a4-a8d9-1426a7e0346c",
      "metadata": {
        "id": "dd2e94c0-fce0-48a4-a8d9-1426a7e0346c"
      },
      "source": [
        "Falls Sie in Colab arbeiten, können Sie mit folgender Zeile die beiden Daten-Dateien zunächst hochladen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a04aeb9b-7fab-4d49-96b6-3ac7c8fc0eff",
      "metadata": {
        "id": "a04aeb9b-7fab-4d49-96b6-3ac7c8fc0eff"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8JM7a7UGqm66",
        "outputId": "dee97505-9a9e-443a-b561-11188e1545a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8JM7a7UGqm66",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "89b31e7b-9a10-424d-b593-ec11b5229de4",
      "metadata": {
        "id": "89b31e7b-9a10-424d-b593-ec11b5229de4",
        "outputId": "da4aa15a-743f-4b78-8317-15d47aa67fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[34.62365962 78.02469282  0.        ]\n",
            " [30.28671077 43.89499752  0.        ]\n",
            " [35.84740877 72.90219803  0.        ]\n",
            " [60.18259939 86.3085521   1.        ]\n",
            " [79.03273605 75.34437644  1.        ]\n",
            " [45.08327748 56.31637178  0.        ]\n",
            " [61.10666454 96.51142588  1.        ]\n",
            " [75.02474557 46.55401354  1.        ]\n",
            " [76.0987867  87.42056972  1.        ]\n",
            " [84.43281996 43.53339331  1.        ]]\n",
            "[0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "data = np.genfromtxt(fname='/content/drive/MyDrive/cvml/assignment_scores.txt',delimiter=',')\n",
        "print(data[:10])\n",
        "print(data[:,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dda35808-c1c4-42d4-9dd1-a79d3ebacf24",
      "metadata": {
        "id": "dda35808-c1c4-42d4-9dd1-a79d3ebacf24"
      },
      "source": [
        "## Erstellen der Designmatrix und Extraktion der Zielvariable\n",
        "Separieren Sie aus den eingelesenen Daten (`data`) Merkmale und Zielvariable und erstellen Sie eine Designmatrix. Die erste Spalte der Designmatrix soll die Elemente `1` enthalten. \n",
        "\n",
        "- **t**: Targets/Zielvektor der Trainingsdaten (Dim.: $n \\times 1$)\n",
        "- **X**: Designmatrix der Trainingsdaten (Dim.: $n \\times m + 1$)\n",
        "\n",
        "Funktionen, die hilfreich sein können: np.hstack(), np.ones()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "746e47cc-30a1-43c2-9b81-e1f06891dfc1",
      "metadata": {
        "id": "746e47cc-30a1-43c2-9b81-e1f06891dfc1",
        "outputId": "0af2bbae-5d30-4415-dc55-f0bae90a9882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.         34.62365962 78.02469282]\n",
            " [ 1.         30.28671077 43.89499752]\n",
            " [ 1.         35.84740877 72.90219803]\n",
            " [ 1.         60.18259939 86.3085521 ]\n",
            " [ 1.         79.03273605 75.34437644]\n",
            " [ 1.         45.08327748 56.31637178]\n",
            " [ 1.         61.10666454 96.51142588]\n",
            " [ 1.         75.02474557 46.55401354]\n",
            " [ 1.         76.0987867  87.42056972]\n",
            " [ 1.         84.43281996 43.53339331]\n",
            " [ 1.         95.86155507 38.22527806]\n",
            " [ 1.         75.01365839 30.60326323]\n",
            " [ 1.         82.30705337 76.4819633 ]\n",
            " [ 1.         69.36458876 97.71869196]\n",
            " [ 1.         39.53833914 76.03681085]\n",
            " [ 1.         53.97105215 89.20735014]\n",
            " [ 1.         69.07014406 52.74046973]\n",
            " [ 1.         67.94685548 46.67857411]\n",
            " [ 1.         70.66150955 92.92713789]\n",
            " [ 1.         76.97878373 47.57596365]\n",
            " [ 1.         67.37202755 42.83843832]\n",
            " [ 1.         89.67677575 65.79936593]\n",
            " [ 1.         50.53478829 48.85581153]\n",
            " [ 1.         34.21206098 44.2095286 ]\n",
            " [ 1.         77.92409145 68.97235999]\n",
            " [ 1.         62.27101367 69.95445795]\n",
            " [ 1.         80.19018075 44.82162893]\n",
            " [ 1.         93.1143888  38.80067034]\n",
            " [ 1.         61.83020602 50.25610789]\n",
            " [ 1.         38.7858038  64.99568096]\n",
            " [ 1.         61.37928945 72.80788731]\n",
            " [ 1.         85.40451939 57.05198398]\n",
            " [ 1.         52.10797973 63.12762377]\n",
            " [ 1.         52.04540477 69.43286012]\n",
            " [ 1.         40.23689374 71.16774802]\n",
            " [ 1.         54.63510555 52.21388588]\n",
            " [ 1.         33.91550011 98.86943574]\n",
            " [ 1.         64.17698887 80.90806059]\n",
            " [ 1.         74.78925296 41.57341523]\n",
            " [ 1.         34.18364003 75.23772034]\n",
            " [ 1.         83.90239366 56.30804622]\n",
            " [ 1.         51.54772027 46.85629026]\n",
            " [ 1.         94.44336777 65.56892161]\n",
            " [ 1.         82.36875376 40.61825516]\n",
            " [ 1.         51.04775177 45.82270146]\n",
            " [ 1.         62.22267576 52.06099195]\n",
            " [ 1.         77.19303493 70.4582    ]\n",
            " [ 1.         97.77159928 86.72782233]\n",
            " [ 1.         62.0730638  96.76882412]\n",
            " [ 1.         91.5649745  88.69629255]\n",
            " [ 1.         79.94481794 74.16311935]\n",
            " [ 1.         99.27252693 60.999031  ]\n",
            " [ 1.         90.54671411 43.39060181]\n",
            " [ 1.         34.52451385 60.39634246]\n",
            " [ 1.         50.28649612 49.80453881]\n",
            " [ 1.         49.58667722 59.80895099]\n",
            " [ 1.         97.64563396 68.86157272]\n",
            " [ 1.         32.57720017 95.59854761]\n",
            " [ 1.         74.24869137 69.82457123]\n",
            " [ 1.         71.79646206 78.45356225]\n",
            " [ 1.         75.39561147 85.75993667]\n",
            " [ 1.         35.28611282 47.02051395]\n",
            " [ 1.         56.2538175  39.26147251]\n",
            " [ 1.         30.05882245 49.59297387]\n",
            " [ 1.         44.66826172 66.45008615]\n",
            " [ 1.         66.56089447 41.09209808]\n",
            " [ 1.         40.45755098 97.53518549]\n",
            " [ 1.         49.07256322 51.88321182]\n",
            " [ 1.         80.27957401 92.11606081]\n",
            " [ 1.         66.74671857 60.99139403]\n",
            " [ 1.         32.72283304 43.30717306]\n",
            " [ 1.         64.03932042 78.03168802]\n",
            " [ 1.         72.34649423 96.22759297]\n",
            " [ 1.         60.45788574 73.0949981 ]\n",
            " [ 1.         58.84095622 75.85844831]\n",
            " [ 1.         99.8278578  72.36925193]\n",
            " [ 1.         47.26426911 88.475865  ]\n",
            " [ 1.         50.4581598  75.80985953]\n",
            " [ 1.         60.45555629 42.50840944]\n",
            " [ 1.         82.22666158 42.71987854]\n",
            " [ 1.         88.91389642 69.8037889 ]\n",
            " [ 1.         94.83450672 45.6943068 ]\n",
            " [ 1.         67.31925747 66.58935318]\n",
            " [ 1.         57.23870632 59.51428198]\n",
            " [ 1.         80.366756   90.9601479 ]\n",
            " [ 1.         68.46852179 85.5943071 ]\n",
            " [ 1.         42.07545454 78.844786  ]\n",
            " [ 1.         75.47770201 90.424539  ]\n",
            " [ 1.         78.63542435 96.64742717]\n",
            " [ 1.         52.34800399 60.76950526]\n",
            " [ 1.         94.09433113 77.15910509]\n",
            " [ 1.         90.44855097 87.50879176]\n",
            " [ 1.         55.48216114 35.57070347]\n",
            " [ 1.         74.49269242 84.84513685]\n",
            " [ 1.         89.84580671 45.35828361]\n",
            " [ 1.         83.48916274 48.3802858 ]\n",
            " [ 1.         42.26170081 87.10385094]\n",
            " [ 1.         99.31500881 68.77540947]\n",
            " [ 1.         55.34001756 64.93193801]\n",
            " [ 1.         74.775893   89.5298129 ]]\n",
            "[0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1.\n",
            " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1.\n",
            " 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "X = np.hstack([np.vstack(np.ones(len(data))),np.vstack(data[:,0]),np.vstack(data[:,1])])\n",
        "print(X)\n",
        "t = np.hstack(data[:,2])\n",
        "print(t)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52169427-a80e-4bf9-ab47-57ff90519a71",
      "metadata": {
        "id": "52169427-a80e-4bf9-ab47-57ff90519a71"
      },
      "source": [
        "## Visualisierung der Daten\n",
        "Stellen Sie die Datenpunkte nun in einem Diagramm dar. Erweitern Sie dafür die bereits vorhandene Funktion in der Art, dass die Datenpunkte entsprechend ihre Klassenzugehörigkeit in unterschiedlichen Farben dargestellt werden (blau/rot = bestanden/nicht bestanden). In der bereits vorhandenen Vorlage werden alle Datenpunkte 2 mal dargestellt, einmal in blau einmal in rot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "320a0e1e-d08d-4407-9611-2717158e0164",
      "metadata": {
        "id": "320a0e1e-d08d-4407-9611-2717158e0164",
        "outputId": "35862726-9c82-4c44-f085-b63fb8bc7f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fb920982650>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(X[:,1],X[:,2],'*',X[:,1],X[:,2],'r*')\n",
        "plt.xlabel('Punktzahl Assignment 1')\n",
        "plt.ylabel('Punktzahl Assignment 2')\n",
        "plt.legend(['bestanden','nicht bestanden'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0a83a1b-0966-4e50-a5b0-16766555660d",
      "metadata": {
        "id": "f0a83a1b-0966-4e50-a5b0-16766555660d"
      },
      "source": [
        "## Hypothesenfunktion der logistischen Regression\n",
        "Die Sigmoid-Funktion ist die Hypothesenfunktion der logistischen Regression. Wir benötigen Sie sowohl zur Realisierung des Gradient-Descent-Verfahrens als auch zur Visualisierung von Entscheidungsgrenzen. Die Hypothesenfunktion ist definiert als\n",
        "\n",
        "$h_{\\mathbf{w}}(\\mathbf{x})=g(\\mathbf{w^T}\\mathbf{x})$\n",
        "\n",
        "$g(z)=\\dfrac{1}{1+e^{-z}}$\n",
        "\n",
        "In dieser Aufgabe realisieren Sie die nichtlineare Transformation der latenten Variablen `z`.\n",
        "\n",
        "\n",
        "### Argumente der Funktion\n",
        "- `z`: latente Variable, Skalar oder Vektor\n",
        "\n",
        "### Rückgabewert\n",
        "- $g(z)$\n",
        "  - Skalar, falls `z` ein Skalar ist\n",
        "  - Vektor, falls `z` ein Vektor ist, d.h. Anwendung der sigmoid-Funktion auf jedes Element des Vektors\n",
        "\n",
        "### Hinweise\n",
        "- Exponentialfunktion: `numpy.exp()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf17cada-e5da-495a-9f3a-8e93a579d399",
      "metadata": {
        "id": "bf17cada-e5da-495a-9f3a-8e93a579d399"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    ...\n",
        "    return ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77463a25-0f3d-4799-8f1f-76f9c2869efe",
      "metadata": {
        "id": "77463a25-0f3d-4799-8f1f-76f9c2869efe"
      },
      "outputs": [],
      "source": [
        "# Test der sigmoid-Funktion. Die Funktion hat an der Stelle 0 den Funtionswert 0.5\n",
        "# Der Aufruf sollte sowohl mit einem Skalar als auch mit einem Vektor funktionieren. Im letzteren Fall liefert die Funktion einen Vektor zurück\n",
        "print(sigmoid(0))\n",
        "print(sigmoid(np.zeros((3,1))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cb58573-dd6b-4f81-928c-078b60a8fb45",
      "metadata": {
        "id": "9cb58573-dd6b-4f81-928c-078b60a8fb45"
      },
      "source": [
        "## Gradient-Descent-Verfahren für die logistische Regression\n",
        "Nun soll die Optimierung der Fehlerfunktion zur logistischen Regression mittels Batch-Gradient-Descent erfolgen. Hierfür werden wie bereits bei der linearen Regression zwei Teilfunktionen benötigt. Anschließen erfolgt unter Verwendung dieser Funktionen die Optimierung der Zielfunktion mittels Gradient-Descent.\n",
        "\n",
        "- **compute_loss(X, t, w)**: Bestimmung des Fehlers des durch den Gewichtsvektor $\\mathbf{w}$ parametrierten Modells für einen gebenen Datensatz ($\\mathbf{X}$, $\\mathbf{t}$)\n",
        "- **do_gradient_step(X, t, w, alpha, lamda)**: Ausführung eines Gradient-Descent-Optimierungsschrittes und Rückgabe eines neuen Gewichtsvektors $\\mathbf{w'}$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1b4f61b-6de3-4e2c-9e19-ee70d5107253",
      "metadata": {
        "id": "f1b4f61b-6de3-4e2c-9e19-ee70d5107253"
      },
      "source": [
        "### Funktion: compute_loss\n",
        "Die Funktion ermittelt den Fehler des durch den Gewichtsvektor $\\mathbf{w}$ parametrierten Modells der logistischen Regression für einen gebenen Datensatz ($\\mathbf{X}$, $\\mathbf{t}$). Die Kostenfunktion der logistischen Regression lautet \n",
        "\n",
        "$$L(\\mathbf{w})=-\\dfrac{1}{n}\\sum_{i=1}^n t^{[i]}\\cdot \\log{g(\\mathbf{w^T} \\mathbf{\\overline{x}}^{[i]})} + (1-t^{[i]}) \\log{(1-g(\\mathbf{w^T} \\mathbf{\\overline{x}}^{[i]})})$$\n",
        "\n",
        "\n",
        "bzw. in vektorisierter Form\n",
        "\n",
        "$$L(\\mathbf{w})=-\\dfrac{1}{n} \\left[ \\log\\left(g(\\mathbf{X}\\mathbf{w})\\right)^T  \\mathbf{t} + \\log(\\mathbf{1} - g(\\mathbf{X}\\mathbf{w}))^T (\\mathbf{1}-\\mathbf{t})\\right]$$\n",
        "\n",
        "Das Symbol $\\mathbf{1}$ entspricht einem Zeilenvektor bestehend aus Einsen. Unter Anwendung der Broadcasting-Funktionalität müssen Sie diesen Vektor aber nicht explizit erzeugen.\n",
        "\n",
        "#### Argumente der Funktion\n",
        "- **X**: Designmatrix (erweitert mit einem $\\mathbf{1}$-Spaltenvektor, Dimensionen: $n \\times (m+1)$)\n",
        "- **t**: Zielvariable ($n x 1$)\n",
        "- **w**: Vektor der Gewichte ($(m+1) \\times 1$)\n",
        "\n",
        "#### Hinweise\n",
        "- Logarithmus: `numpy.log()`\n",
        "- Der Rückgabewert der `numpy.log()`-Funktion ist `inf` für `log(0)` und `nan` für `log(<0)`. Im vorbereiteten Code-Gerüst werden ggf. resultierenden `nan`-Werte in `inf`-Werte überführt, sodass der Rückgabewert der `compute_loss()`-Funktion enweder ein reellwertiger Kostenwert oder alternativ `inf` ist."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "722df05b-9699-471b-82b5-ee59f343c6ff",
      "metadata": {
        "id": "722df05b-9699-471b-82b5-ee59f343c6ff"
      },
      "outputs": [],
      "source": [
        "def compute_loss(w, X, t):\n",
        "    \n",
        "    ...\n",
        "    L = ...\n",
        "    if np.isnan(L):\n",
        "        return np.inf\n",
        "    return L"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b076011-8c18-4036-a20f-1db11af15323",
      "metadata": {
        "id": "5b076011-8c18-4036-a20f-1db11af15323"
      },
      "source": [
        "### Funktion: do_gradient_step\n",
        "\n",
        "Die Funktion führt einen Optimierungsschritt des Batch-Gradient-Descent-Verfahrens mit Regularisierung ($\\lambda \\geq 0$) und aktualisiert die Parameter des Gewichtsvektors $\\mathbf{w}$ entsprechend der Update-Regel. Implementieren Sie die Update-Regel für die logistische Regression entweder als Summenformel oder mithilfe der Matrixnotation (siehe unten). Ausgangspunkt ist dabei die Gradient-Descent-Funktion aus dem Assignment zur linearen Regression, die hier enstprechend zu erweitern ist.\n",
        "\n",
        "__Argumente der Funktion__:\n",
        "- **X**: Designmatrix (erweitert mit einem $\\mathbf{1}$-Spaltenvektor, Dimensionen: $n \\times (m+1)$)\n",
        "- **t**: Zielvariable ($n x 1$)\n",
        "- **w**: Vektor der Gewichte ($(m+1) \\times 1$)\n",
        "- **alpha** (**$\\alpha$**): Lernrate\n",
        "- **lamda** (**$\\lambda$**): Regularisierungsparameter\n",
        "\n",
        "__Rückgabewerte__:\n",
        "  - $\\mathbf{w'}$ nach Iterationsschritt\n",
        "  \n",
        "__Gradient-Optimierungsschritt__ als Summenformel:\n",
        "\n",
        "$$\\mathbf{w^{'}}=\\mathbf{w}-\\dfrac{\\alpha}{n} \\left[ \\sum_{i=1}^n \\mathbf{\\overline{x}}^{[i]}\\left(g\\left(\\mathbf{\\overline{x}}^{T^{[i]}} \\mathbf{w}\\right)-t^{[i]}\\right) + \\lambda \\mathbf{w} \\right]$$\n",
        "\n",
        "__Gradient-Optimierungsschritt__ in Matrixnotation:\n",
        "\n",
        "$$\\mathbf{w'} := \\mathbf{w} - \\dfrac{\\alpha}{n} \\left[\\mathbf{\\overline{X}^T}\\left(g\\left(\\mathbf{\\overline{X}}\\mathbf{w}\\right) - \\mathbf{t}\\right) + \\lambda \\mathbf{w}\\right]$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e810fd85-8a78-4fdf-afe5-209c89166870",
      "metadata": {
        "id": "e810fd85-8a78-4fdf-afe5-209c89166870"
      },
      "outputs": [],
      "source": [
        "def do_gradient_step(X, t, w, alpha, lamda):\n",
        "    n = len(t)\n",
        "    t = t.reshape(n,1)\n",
        "    # Erweiterung der nachfolgenden Zeile so, dass sie der Update-Regel der logistischen Regression entspricht\n",
        "    w = w - alpha/n * (X.T@(X @ w - t) + lamda * w)  \n",
        "    return w"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ae840948-a696-4748-bb9c-4d4cc3118dec",
      "metadata": {
        "id": "ae840948-a696-4748-bb9c-4d4cc3118dec"
      },
      "source": [
        "### Optimierung mit Batch Gradient Descent\n",
        "Auf Basis der Funktion zur Bestimmung der Kostenfunktion und __eines__ Optimierungsschrittes des Gradient-Descent-Verfahrens kann nun eine iterative Optimierung erfolgen. Dazu kann die bereits im Rahmen der linearen Regression entwickelte Funktion verwendet werden. Führen Sie nachfolgende Zelle aus, um einen optimalen Gewichtsvektors $\\mathbf{w}$ durch Minimierung der Fehlerfunktion der logistischen Regression mit dem Batch-Gradient-Descent-Verfahren in `steps` Optimierungsschritten und mit der Lernrate $\\alpha$ zu bestimmen. In der Zelle muss kein Code ergänzt werden.\n",
        "\n",
        "- Variieren Sie die Lernrate und beobachten Sie am Optimierungsergebnis sowie am Verlauf der Kostenfunkion, wie schnell die Optimierung instabil wird und nicht mehr konvergiert, d.h. das kein Minimum mehr gefunden werden kann. Durch die Nichtlinearität der Sigmoid-Funktion ist die Optimierung mit dem Gradient-Descent-Verfahen nicht ideal.\n",
        "- Variieren Sie zu einem späteren Zeitpunkt die Regularisierung und beobachten Sie für die ermittelten Parameter den Verlauf der Entscheidungsgrenze und wie sich diese verändert.\n",
        "\n",
        "#### Hinweise\n",
        "- erwartete Lösung: $\\mathbf{w} \\approx [-25.2, 0.2, 0.2]^T$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27c6e2ad-79f1-4d5a-9f79-aa6776ce1dc7",
      "metadata": {
        "id": "27c6e2ad-79f1-4d5a-9f79-aa6776ce1dc7"
      },
      "outputs": [],
      "source": [
        "n, d = X.shape\n",
        "steps =  2000000 # max. Anzahl Interationen\n",
        "alpha = 0.004 # Lernrate\n",
        "lamda=1e-8 # regularization: 1e-8 ... 1e2 / 1e-1 = shifted boundary\n",
        "\n",
        "L_train = np.zeros(steps).reshape(steps, 1)\n",
        "\n",
        "# Initialisierung der Gewichte mit zufälligen Werten\n",
        "w = np.random.normal(loc=np.zeros((3,1)), scale=1).reshape(d, 1)\n",
        "\n",
        "for id, step in enumerate(range(steps)):\n",
        "    w = do_gradient_step(X, t, w, alpha, lamda)\n",
        "    L_train[id,0] = compute_loss(w, X, t)\n",
        "\n",
        "w_opt = w\n",
        "    \n",
        "print(w_opt)\n",
        "\n",
        "plt.plot(range(steps),L_train)\n",
        "plt.ylabel('log-Error')\n",
        "plt.xlabel('#Iterations')\n",
        "plt.legend(['Train Loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07e52861-0786-452f-814e-9aef821f88bc",
      "metadata": {
        "id": "07e52861-0786-452f-814e-9aef821f88bc"
      },
      "source": [
        "### [Optional] Ergänzung zur Optimierung\n",
        "Eine Alternative zur eigenen Implementierung einer Optimierungsfunktion ist die Verwendung verfügbarer Implementierungen wie beispielsweise der scipy-Funktion `fmin`, in der die Optimierung einer Kostenfunktion nach dem Downhill-Simplex-Verfahren realisiert wird. Dieses spezielle Verfahren nutzt eine Minimierungsstrategie, die völlig ohne Gradienten auskommt. Die folgende Zelle zeigt, wie Sie auf Basis der oben programmierten Kostenfunktion `compute_loss` eine Optimierung umsetzen können.\n",
        "\n",
        "Weitere Argumente der Minimierungsfunktion, mit denen das Optimierungsverhalten beeinflusst werden kann, finden Sie hier: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin.html\n",
        "\n",
        "#### Hinweise\n",
        "- Unter Umständen erscheint die Warnung, dass die Anzahl maximaler Iterationen erreicht wurde. Die Optimierung bricht dann ab. Führen Sie die Zelle dann weitere Male aus, die Funktion sollte bei richtiger Umsetzung der `compute_loss()`-Funktion häufig konvergieren. Alternativ können Sie mit dem Argrumen `maxiter=` die Anzahl der Iterationen erhöhen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b12e24-ed0a-4f3d-9929-c5a5ea431f78",
      "metadata": {
        "id": "e7b12e24-ed0a-4f3d-9929-c5a5ea431f78"
      },
      "outputs": [],
      "source": [
        "from scipy.optimize import fmin\n",
        "n, d = X.shape\n",
        "\n",
        "# Initialisierung der Gewichte mit zufälligen Werten\n",
        "w_init = np.random.normal(loc=np.zeros((3,1)), scale=1).reshape(d, 1)\n",
        "\n",
        "# Die Argumente der fmin-Funktion sind die \"Adresse\" der Kostenfunktion `compute_loss`, \n",
        "# die Startwerte für die in dieser Funktion zu optimierenden Parameter sowie weitere Parameter, \n",
        "# welche für die Kostenfunktion notwendig sind. Das erste Argument der Kostenfunktion muss den zu optimierenden Parametern entsprechen (bei uns w).\n",
        "w_opt = fmin(compute_loss, w_init, args=(X,t))\n",
        "print(w_opt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d3a5e3d-ff9b-4e4f-b0ad-ad53c8a6c935",
      "metadata": {
        "id": "1d3a5e3d-ff9b-4e4f-b0ad-ad53c8a6c935"
      },
      "source": [
        "## Visualisierung der Entscheidungsgrenze\n",
        "Das Argument $z=\\mathbf{w^T}\\mathbf{x}$ der Hypothesenfunktion $h_{\\mathbf{w}}(\\mathbf{x})=g(z)$ können wir als Entscheidungsgrenze interpretieren. Da die Sigmoid-Funktion an der Stelle 0 den Funktionswert 0.5 hat, können wir die Entscheidungsgrenze im Merkmalsraum darstellen, indem wir die lineare Gleichung $z=0=\\mathbf{w^T}\\mathbf{x}$ nach einem der beiden Merkmale auflösen und die Funktion im Merkmalsraum evaluieren, z.B.\n",
        "$$x_2 = -\\dfrac{w_1}{w_2} x_1 -\\dfrac{w_0}{w_2}$$\n",
        "\n",
        "Wenn wir die Variable $x_1$ nun im Bereich von 0 bis 100 abtasten, können wir entsprechend der Gleichung die zugehörigen Funktionswerte der Entscheidungsgrenze bestimmen und dann visualisieren.\n",
        "\n",
        "Eine Alternative, die insbesondere bei nichtlinearen Zusammenhängen besser geeignet ist, ist die Evaluierung der Hypothesenfunktion selbst. Da wir als Entscheidungsschwelle zunächst $h_{\\mathbf{w}}(\\mathbf{x})=0.5$ verwenden, können wir die Hypothesenfunktion für jeden Punkt im Merkmalsraum bestimmen und dann die Stellen visualisieren, an denen der Funktionswert 0.5 beträgt. Dazu ist es erforderlich, den Merkmalsraum im interessanten Bereich von 0 bis 100 (Punkzahlen) entlang jeder Mermalsachse (Punkzahl Assignment 1 & 2) abzutasten und für jede Merkmalskombination den Funktionswert der Hypothesenfunktion zu bestimmen. \n",
        "\n",
        "Das Abtasten kann mit der Funktion `np.meshgrid()` erfolgen und ist im nachstehenden Codegerüst schon vorbereitet. Die entstehenden Arrays `xx1` und `xx2` enthalten jeweils 100 Wiederholungen der Vektoren, mit denen der Merkmalsbereich abgetastet wurde. Es entsteht also jeweils eine Matrix der Dimension 100 Abtastwerte x 100 Wiederholungen, also 100 x 100. Im Array `xx1` sind dies Spaltenvektoren, im Array `xx2` Zeilenvektoren. Durch dieses Arrangement finden wir eine spezifische Merkmalskombination (also __einen__ Punkt aller möglichen Kombinationen im Merkmalsraum), in dem wir in beiden Matrizen auf das Element (i,j) zugreifen, d.h. `xx1(i,j)` und `xx2(i,j)` bilden ein Koordinatenpaar im Merkmalsraum.\n",
        "\n",
        "Ihre Aufgabe ist es, diese 2D-Matrizen in 1D-Vektoren umzuwandeln (d.h. eine Parameterkombination findet sich dann jeweils in der gleichen Zeile der Vektoren) und dann für jede der Parameterkombinationen die Hypothesenfunktion zu bestimmen. Sie erhalten also einen Vektor der Hypothesenfunktion mit 10.000 Elementen. Das Codegerüst wird diesen Vektor analog zu den Arrays `xx1` und `xx2` in ein 2D-Array umwandeln. Anschließend werden mithilfe der Funktion `contour()` alle diejenigen Orte visualisiert, an denen sich als Funktionswert der Hypothesenfunktion 0.5 ergibt, d.h. unsere Entscheidungsgrenze.\n",
        "\n",
        "\n",
        "### Hinweise\n",
        "- Ein Array kann mit der Funktion np.ravel() bzw. np.flatten() kollabiert werden, d.h. in ein 1D-Array umgewandelt werden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945cf10f-e9c9-4b93-abb0-dc442385b217",
      "metadata": {
        "id": "945cf10f-e9c9-4b93-abb0-dc442385b217"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary(w_opt, X, t):\n",
        "    x1 = np.linspace(X[:,1].min(),X[:,1].max(),100)\n",
        "    x2 = np.linspace(X[:,2].min(),X[:,2].max(),100)\n",
        "\n",
        "    xx1, xx2 = np.meshgrid(x1, x2)\n",
        "\n",
        "    h = sigmoid(#<Your code here>)\n",
        "\n",
        "    hh = h.reshape(xx1.shape)\n",
        "\n",
        "    plt.plot(X[t==1,1],X[t==1,2],'*',X[t==0,1],X[t==0,2],'r*')\n",
        "    plt.contour(xx1,xx2,hh,[0.5])\n",
        "    plt.xlim([X[:,1].min(),100])\n",
        "    plt.ylim([X[:,2].min(),100])\n",
        "    plt.xlabel('Punktzahl Assignment 1')\n",
        "    plt.ylabel('Punktzahl Assignment 2')\n",
        "    plt.legend(['bestanden','nicht bestanden'])\n",
        "    \n",
        "plot_decision_boundary(w_opt, X, t)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec717160-c06a-437f-9e5f-3b8d3ccb5376",
      "metadata": {
        "tags": [],
        "id": "ec717160-c06a-437f-9e5f-3b8d3ccb5376"
      },
      "source": [
        "## Logistische Regression mit sklearn\n",
        "Die logistische Regression ist als Machine-Learning-Modell in sklearn verfügbar. Unter Verwendung dieser Funktion soll hier die Lösung des bereits oben betrachteten Klassifikationsproblems bestimmt werden.\n",
        "\n",
        "__Teilaufgaben__:\n",
        "  - Realisierung der logistischen Regression mit sklearn\n",
        "    - Instanziieren eines Modell der logistischen Regression mit `LogisticRegression()`\n",
        "    - Trainieren des Modells mit der `fit()`-Funktion\n",
        "    - Speichern der ermittelten Modellparameter in der Variable `w_opt`\n",
        "  - Darstellung der Entscheidungsgrenze auf Basis der oben programmierten Funktion `plot_decision_boundary()`\n",
        "  - Ausgabe der Performance auf den Trainingsdaten in Form eines \"Klassifikationsberichts\" (siehe Hinweise)\n",
        "    \n",
        "__Hinweise__:\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "- __Beachte__: Der uns bekannte Regularisierungsparameter $\\lambda$ wird in der logistischen Regressionsfunktion in sklearn über den Parameter `C` realisiert, der allerings __umgekehrt proportional__ zur Regularisierung ist! D.h. ein großer Wert entspricht geringer Regularisierung und umgekehrt.\n",
        "- Wenn in der Design-Matrix in der ersten Spalte bereits der 1er-Vektor für den notwendigen Offset ergänzt wurde, muss das Modell mit dem Argument `fit_intercept=False` optimiert werden. Ansonsten ist das Argument `fit_intercept=True` erforderlich.\n",
        "- Den durch das Modell ermittelten Offset sowie die ermittelten Gewichte der Merkmale sind in den Variablen `<model>.intercept_` und `<model>.coef_` verfügbar\n",
        "- Klassifikationsbericht: Funktion `classification_report()` aus dem metrics-Modul von sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2999edff-c73e-4c18-b5e4-47c64d2655bd",
      "metadata": {
        "id": "2999edff-c73e-4c18-b5e4-47c64d2655bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "553219a4-c23a-48b7-9b75-5f1a5808472f",
      "metadata": {
        "tags": [],
        "id": "553219a4-c23a-48b7-9b75-5f1a5808472f"
      },
      "outputs": [],
      "source": [
        "# Instanziiere ein Modell\n",
        "m_lr = ...\n",
        "\n",
        "# Trainiere das Modell\n",
        "#<Your code here>\n",
        "\n",
        "# Speichere die ermittelten Parameter\n",
        "w_opt = \n",
        "print(w_opt)\n",
        "\n",
        "# Zeige Entscheidungsgrenze an\n",
        "#<Your code here>\n",
        "\n",
        "# Gib die Performance des Modells auf den Trainingsdaten an\n",
        "# <Your code here>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b28c36a-98a5-471e-859d-a07fb2b050df",
      "metadata": {
        "id": "6b28c36a-98a5-471e-859d-a07fb2b050df"
      },
      "source": [
        "# Logistische Regression nicht linear separierbaren Daten mit sklearn\n",
        "In diesem zweiten fiktiven Szenario soll ein logistisches Regressionsmodell mit sklearn zur Klassifikation nichtlinearer Merkmale realisiert werden.\n",
        "Als Datenquelle dient ebenfalls eine txt-Datei. Sie beinhaltet Daten über das Ergebnis zwei verschiedener Tests, denen Microchips im Rahmen einer Qualitätsprüfung unterzogen werden. Aus den Ergebnissen der Tests soll vorhergesagt werden, ob ein Microchip verkauft werden kann oder aussortiert werden sollte. Die historischen Daten enthalten das Ergebnis, das einzelne Chips in diesen beiden Tests erreicht haben und eine Information darüber, ob die Produkte im Einsatz nach kurzer Zeit ausgefallen sind. Der Zusammenhang zwischen den Merkmalen und den Klassenzuordnungen ist im Gegensatz zum oben stehenden Beispiel nichtlinear."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ae32634-36b3-439c-9204-9cb8db58e221",
      "metadata": {
        "id": "1ae32634-36b3-439c-9204-9cb8db58e221"
      },
      "source": [
        "## Einlesen der Daten\n",
        "Verwenden Sie für das Einlesen der Daten die gleiche Lösung wie für den weiter oben bearbeiteten Datensatz mit linear separierbaren Klassen! Die Daten befinden sich in der Datei `microchip_tests.txt`\n",
        "\n",
        "### Ergebnis\n",
        "- **data**:  Daten für das Training der logistischen Regression\n",
        "- Dimensionen des numpy-Arrays:\n",
        "  - Spalte 1: Funktionstest 1\n",
        "  - Spalte 2: Funktionstest 2\n",
        "  - Spalte 3: Qualitätskontrolle des Chips bestanden  ($y=1$) oder nicht bestanden ($y=0$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b47e42b-2a6c-4808-ac56-b3cece47b300",
      "metadata": {
        "id": "3b47e42b-2a6c-4808-ac56-b3cece47b300"
      },
      "outputs": [],
      "source": [
        "data = \n",
        "print(data[:10], ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e14be05-dcdd-4b57-a141-f11a5b6e71cc",
      "metadata": {
        "id": "9e14be05-dcdd-4b57-a141-f11a5b6e71cc"
      },
      "source": [
        "## Erstellen der Designmatrix und Extraktion der Zielvariable\n",
        "Separieren Sie aus den eingelesenen Daten (`data`) Merkmale und Zielvariable und erstellen Sie eine Designmatrix. __Verzichten Sie diesemal auf das Einfügen einer zusätzlichen Spalte mit den Elementen `1`!__\n",
        "Verwenden Sie ansonsten ebenfalls die bereits weiter oben entwickelte Lösung.\n",
        "\n",
        "- **t**: Targets/Zielvektor der Trainingsdaten (Dim.: $n \\times 1$)\n",
        "- **X**: Designmatrix der Trainingsdaten (Dim.: $n \\times m$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89a95e49-1861-4dea-8b3f-55449b21163a",
      "metadata": {
        "id": "89a95e49-1861-4dea-8b3f-55449b21163a"
      },
      "outputs": [],
      "source": [
        "# <Your MODIFIED code from above>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b5472a4-0638-4400-b032-f2a9e7dcfd6b",
      "metadata": {
        "id": "6b5472a4-0638-4400-b032-f2a9e7dcfd6b"
      },
      "source": [
        "## Visualisierung der Daten\n",
        "Die Visualisierung der Datenpunkte erfolgt ebenfalls genau wie zuvor. Kopieren Sie ihre Lösung von oben und passen Sie diese an (die Spaltenindizes sind aufgrund der fehlenden Spalte mit Einsen anders) und stellen Sie die Datenpunkte entsprechend ihrer Klassenzugehörigkeit zum Aussortieren (rot) und für den Verkauf geeignet (blau) dar. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f245089d-d60d-42c0-9af4-7da70c63ed3a",
      "metadata": {
        "id": "f245089d-d60d-42c0-9af4-7da70c63ed3a"
      },
      "outputs": [],
      "source": [
        "# <Your Code from above>\n",
        "plt.xlabel('Microchip Test 1')\n",
        "plt.ylabel('Microchip Test 2')\n",
        "plt.legend(['verkaufen','aussortieren'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f835aa8f-72e5-4aa5-8250-f75b2c84ec44",
      "metadata": {
        "id": "f835aa8f-72e5-4aa5-8250-f75b2c84ec44"
      },
      "source": [
        "## Generieren nichtlinearer Merkmale\n",
        "Ganz offensichtlich können wir in diesem Beispiel keine lineare Separierung der Klassen vornehmen. Um eine nichtlineare Grenze zwischen den einigermaßen konzentrisch angeordneten Klassen zu bestimmen, können wir unsere Merkmale in einen höher dimensionalen Merkmalsraum mit nichtlinearen Basisfunktionen transformieren, in dem dann eine lineare Separierung möglich ist. Konkret soll jedes ursprüngliche Merkmal in polynomiale Merkmale bis zur Ordnung $p$ transformiert und jeweils gemeinsam mit allen polynomialen Merkmalen des anderen Merkmals ein neues nichtlineares Merkmal bilden. Für genau diese Operation existiert im `preprocessing`-Modul von sklearn die Klasse `PolynomialFeatures`.\n",
        "\n",
        "Um diese Klasse zu verwenden, muss genau wie bei einem Machine-Learning Modell ein Objekt der Klasse instanziiert werden. Anschließend werden beim Aufruf der `fit_transform`-Funktion die ihr übergebenen Daten entsprechend der Initialisierung transformiert. Der nachstehende Code realisiert genau diese Funktionalität. \n",
        "\n",
        "Variieren Sie die Ordnung der Polynome und werfen Sie einen Blick auf die Dimension und die Elemente der neuen Merkmalsmatrix. Betrachten Sie dabei u.a. auch die erste Spalte.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0da48bc4-1753-4e1b-8886-742cb9f336fb",
      "metadata": {
        "id": "0da48bc4-1753-4e1b-8886-742cb9f336fb"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=6)\n",
        "XX = poly.fit_transform(X);\n",
        "\n",
        "# shape von XX und Elemente von XX betrachten\n",
        "# <Your Code here>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "081536da-dc01-4dd6-88c6-0c172e3326c8",
      "metadata": {
        "tags": [],
        "id": "081536da-dc01-4dd6-88c6-0c172e3326c8"
      },
      "source": [
        "## Logistische Regression mit sklearn\n",
        "Trainieren Sie nun mit den nichtlinearen Merkmalen ein logistisches Regressionsmodell. Die grundsätzliche Vorgehensweise ist analog zur Lösung, die in der ersten Teilübung weiter oben entwickelt wurde. __Die Entscheidungsgrenze stellen wir noch nicht dar.__\n",
        "\n",
        "__Teilaufgaben__:\n",
        "  - Realisierung der logistischen Regression mit sklearn\n",
        "    - Instanziieren eines Modell der logistischen Regression mit `LogisticRegression()`\n",
        "    - Trainieren des Modells mit der `fit()`-Funktion\n",
        "    - Speichern der ermittelten Modellparameter in der Variable `w_opt`\n",
        "  - Ausgabe der Performance auf den Trainingsdaten in Form eines Klassifikationsberichts\n",
        "    \n",
        "__Hinweise__:\n",
        "- Eventuell wird eine Warnung ausgegeben, dass der Optimierungsalgorithmus die maximale Anzahl an Iterationen erreicht hat und dadurch beendet wurde. Mit dem Argument `max_iter=` kann die maximale Anzahl an Iterationsschritten variiert werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f6a21c-d178-45c2-a937-9b4de3e83503",
      "metadata": {
        "id": "88f6a21c-d178-45c2-a937-9b4de3e83503"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03cbaf8d-522f-4b3a-8a10-8a59f1327098",
      "metadata": {
        "tags": [],
        "id": "03cbaf8d-522f-4b3a-8a10-8a59f1327098"
      },
      "outputs": [],
      "source": [
        "# Instanziiere ein Modell\n",
        "m_lr = ...\n",
        "\n",
        "# Trainiere das Modell\n",
        "#<Your code here>\n",
        "\n",
        "# Speichere die ermittelten Parameter\n",
        "w_opt = \n",
        "print(w_opt)\n",
        "\n",
        "# Gib die Performance des Modells auf den Trainingsdaten an\n",
        "# <Your code here>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c362ffd-d21c-4694-9fd8-e33c1c972900",
      "metadata": {
        "id": "3c362ffd-d21c-4694-9fd8-e33c1c972900"
      },
      "source": [
        "## Nichtlineare Entscheidungsgrenze visualisieren\n",
        "Die oben bereits programmierte Funktion `plot_decision_boundary()` kann nicht unmittelbar zur Visualisierung der Entscheidungsgrenze verwendet werden. Das liegt daran, dass die Funktion für die jeweilige Merkmalskombination nur lineare \n",
        "\n",
        "Erweitern Sie das unten stehende Code-Gerüst so, dass aus den generierten Merkmalsvektoren `xx1` und `xx2` zunächst polynomiale Merkmale erzeugt werden, bevor die Hypothesenfunktion bestimmt wird. Um dies umzusetzen besitzt die neue Funktion `plot_decision_boundary_nonlinear()` nun ein weiteres Argument namens `poly`, wobei es sich um einen Zeiger auf das weiter oben instanziierte Objekt der Klasse PolynomialFeatures handelt. Innerhalb der neuen Funktion können Merkmale also ebenfalls mit der Funktion `poly.fit_transform()` transformiert werden.\n",
        "\n",
        "Sobald die Entscheidungsgrenze visualisiert wird, verändern Sie das logistische Regressionsmodell durch Anpassung des Regularisierungsparameters (`C`) und beobachten Sie, wie sich die Entscheidungsgrenze ändert. Veränderung Sie außerdem die Anzahl der für das Modell verwendeten polynomialen Merkmale (Ordnung der Polynome anpassen)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "786ec683-0d4f-4c00-bdfb-75fbb9f49719",
      "metadata": {
        "id": "786ec683-0d4f-4c00-bdfb-75fbb9f49719"
      },
      "outputs": [],
      "source": [
        "def plot_decision_boundary_nonlinear(w_opt, X, t, poly):\n",
        "\n",
        "    x1 = np.linspace(X[:,1].min(),X[:,1].max(),100)\n",
        "    x2 = np.linspace(X[:,2].min(),X[:,2].max(),100)\n",
        "\n",
        "    xx1, xx2 = np.meshgrid(x1, x2)\n",
        "\n",
        "    h = sigmoid(#<Your MODIFIED code from above)\n",
        "    \n",
        "    hh = h.reshape(xx1.shape)\n",
        "    \n",
        "    plt.plot(X[t==1,1],X[t==1,2],'*',X[t==0,1],X[t==0,2],'r*')\n",
        "    plt.contour(xx1,xx2,hh,[0.5])\n",
        "    plt.xlim(-1,1)\n",
        "    plt.ylim(-1,1.3)\n",
        "    plt.xlabel('Microchip Test 1')\n",
        "    plt.ylabel('Microchip Test 2')\n",
        "    plt.legend(['verkaufen','aussortieren'])\n",
        "    \n",
        "plot_decision_boundary_nonlinear(w_opt, XX, t, poly)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9c49706-c008-4525-a397-caf444d73dcb",
      "metadata": {
        "id": "d9c49706-c008-4525-a397-caf444d73dcb"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "name": "logistic_regression.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}